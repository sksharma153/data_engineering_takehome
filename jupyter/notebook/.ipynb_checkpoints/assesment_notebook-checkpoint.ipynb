{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, isnan, when, count, avg, min, max, stddev, year, row_number, to_date, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder. \\\n",
    "    appName(\"pyspark-1\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/dataset/nyc-jobs.csv\", header=True)\n",
    "#df.printSchema()\n",
    "\n",
    "#df.show(5)\n",
    "\n",
    "#print(f\"Total number for rows: {df.count()}\")\n",
    "\n",
    "#df.describe().show()\n",
    "\n",
    "#df.select([count(when(col(c).isNull() | isnan(c) | (col(c) == ''), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "#df.select(\"Job Category\").distinct().show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_salary_frequency(df) -> list:\n",
    "    row_list = df.select('Salary Frequency').distinct().collect()\n",
    "    return [row['Salary Frequency'] for row in row_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.withColumn(\"Salary Range From\", col(\"Salary Range From\").cast(\"double\"))\\\n",
    "        .withColumn(\"Salary Range To\", col(\"Salary Range To\").cast(\"double\"))\n",
    "    df = df.withColumn(\"Salary Mean\", (col(\"Salary Range From\")+col(\"Salary Range To\")) / 2)\\\n",
    "            .withColumn(\"Posting Date\", to_date(col(\"Posting Date\"), 'yyyy-MM-dd'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_jobs_per_category(df): \n",
    "    return df.groupBy('Job Category').count().orderBy(\"count\", ascending=False).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_distribution_per_category(df):\n",
    "    return df.groupBy('Job Category').agg(avg(\"Salary Mean\").alias(\"avg_salary\"),\n",
    "                                         min(\"Salary Mean\").alias(\"min_salary\"),\n",
    "                                         max(\"Salary Mean\").alias(\"max_salary\"),\n",
    "                                         stddev(\"Salary Mean\").alias(\"stddev_salary\")\n",
    "                                         ).orderBy(\"avg_salary\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_salary_per_agency(df):\n",
    "    window_specs = Window.partitionBy(\"Agency\").orderBy(col(\"Salary Mean\").desc())\n",
    "    return df.withColumn(\"rank\", row_number().over(window_specs)\n",
    "                        ).filter(col(\"rank\") == 1\n",
    "                                ).select(\"Agency\", \"Job Category\", \"Salary Mean\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_2year_avg_salary_agency(df):\n",
    "    max_year = df.select(year(col(\"Posting Date\")).alias(\"year\")).agg(max(\"year\").alias(\"max_year\")).collect()[0][\"max_year\"]\n",
    "    recent_df = df.filter(year(col(\"Posting Date\")) > (max_year-2))\n",
    "    return recent_df.groupBy(\"Agency\").agg(avg(\"Salary Mean\").alias(\"avg_salary\")\n",
    "                                          ).orderBy(col(\"avg_salary\").desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_paid_skills_us(df):\n",
    "    skills_keywords = ['Python', 'SQL','Java','Spark','AWS','Azure','GCP','Kubernetes','Docker','Tableau','Power BI', 'Snowflake','Databricks', 'Pandas']\n",
    "    for skill in skills_keywords:\n",
    "        df = df.withColumn(skill, when(col(\"Job Description\").rlike(f\"(?i){skill}\"), 1).otherwise(0))\n",
    "    paid_per_skills = {}\n",
    "    for skill in skills_keywords:\n",
    "        paid_per_skills[skill] = df.filter(col(skill) == 1).agg(avg(\"Salary Mean\").alias(f\"{skill}_avg_salary\")).collect()[0][0]\n",
    "    return pd.DataFrame(paid_per_skills.items(), columns=['Skills', 'Salary'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_useless_values(df):\n",
    "    total_rows = df.count()\n",
    "    null_counts = df.select([\n",
    "        count(\n",
    "            when(col(c).isNull() | isnan(col(c)) | (col(c) == ''), c)\n",
    "        ).alias(c) \n",
    "        for c in df.columns\n",
    "    ])\n",
    "    null_ratios = null_counts.collect()[0].asDict()\n",
    "    column_to_drop = [col_name for col_name, nulls in null_ratios.items() if nulls/total_rows > 0.5]\n",
    "    print(\"Drpping Columns : \", column_to_drop)\n",
    "    \n",
    "    return df.drop(*column_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_target(df, output_path:str):\n",
    "    df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "def visualize_result(df, x_col, y_col=None, title=''):\n",
    "    if isinstance(df, DataFrame):\n",
    "        pd_df = df.toPandas()\n",
    "    else:\n",
    "        pd_df = df\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=pd_df, x=x_col, y=y_col, palette=\"magma\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrec_df = top_10_jobs_per_category(df)\\nrec_df.show(5)\\nvisualize_result(rec_df, x_col=\\'count\\', y_col=\"Job Category\", title=\"Top 10 Salary\")\\n\\nsalary_per_cat_df=salary_distribution_per_category(df).limit(10)\\nsalary_per_cat_df.show(5)\\nvisualize_result(salary_per_cat_df, x_col=\\'avg_salary\\', y_col=\\'Job Category\\', title=\\'Average Salary distribution per catagory\\')\\nvisualize_result(salary_per_cat_df, x_col=\\'min_salary\\', y_col=\\'Job Category\\', title=\\'Min Salary distribution per catagory\\')\\nvisualize_result(salary_per_cat_df, x_col=\\'max_salary\\', y_col=\\'Job Category\\', title=\\'max Salary distribution per catagory\\')\\nvisualize_result(salary_per_cat_df, x_col=\\'stddev_salary\\', y_col=\\'Job Category\\', title=\\'stddevSalary distribution per catagory\\')\\n\\nhighest_sal_df = highest_salary_per_agency(df)\\nvisualize_result(highest_sal_df.limit(10), x_col=\\'Salary Mean\\', y_col=\\'Agency\\', title=\\'highest Salary as per Agency\\')\\n\\nlast2_year_avg_sal_df = last_2year_avg_salary_agency(df)\\nvisualize_result(last2_year_avg_sal_df.limit(10), x_col=\\'avg_salary\\', y_col=\\'Agency\\', title=\\'Average Salary as per Agency\\')\\n\\nskills_paid_df = highest_paid_skills_us(df)\\nvisualize_result(skills_paid_df, x_col=\\'Salary\\', y_col=\\'Skills\\', title=\\'Sallary Based on Skills\\')\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=remove_useless_values(df)\n",
    "df=clean_data(df)\n",
    "df.count()\n",
    "output_path = \"./output/process_file\"\n",
    "write_data_to_target(df, output_path)\n",
    "'''\n",
    "rec_df = top_10_jobs_per_category(df)\n",
    "rec_df.show(5)\n",
    "visualize_result(rec_df, x_col='count', y_col=\"Job Category\", title=\"Top 10 Salary\")\n",
    "\n",
    "salary_per_cat_df=salary_distribution_per_category(df).limit(10)\n",
    "salary_per_cat_df.show(5)\n",
    "visualize_result(salary_per_cat_df, x_col='avg_salary', y_col='Job Category', title='Average Salary distribution per catagory')\n",
    "visualize_result(salary_per_cat_df, x_col='min_salary', y_col='Job Category', title='Min Salary distribution per catagory')\n",
    "visualize_result(salary_per_cat_df, x_col='max_salary', y_col='Job Category', title='max Salary distribution per catagory')\n",
    "visualize_result(salary_per_cat_df, x_col='stddev_salary', y_col='Job Category', title='stddevSalary distribution per catagory')\n",
    "\n",
    "highest_sal_df = highest_salary_per_agency(df)\n",
    "visualize_result(highest_sal_df.limit(10), x_col='Salary Mean', y_col='Agency', title='highest Salary as per Agency')\n",
    "\n",
    "last2_year_avg_sal_df = last_2year_avg_salary_agency(df)\n",
    "visualize_result(last2_year_avg_sal_df.limit(10), x_col='avg_salary', y_col='Agency', title='Average Salary as per Agency')\n",
    "\n",
    "skills_paid_df = highest_paid_skills_us(df)\n",
    "visualize_result(skills_paid_df, x_col='Salary', y_col='Skills', title='Sallary Based on Skills')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = [('A', 'Annual'), ('B', 'Daily')]\n",
    "expected_result = ['Annual', 'Daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_salary_frequency(mock_data: list, \n",
    "                              expected_result: list,\n",
    "                              schema: list = ['id', 'Salary Frequency']):  \n",
    "    mock_df = spark.createDataFrame(data = mock_data, schema = schema)\n",
    "    #assert get_salary_frequency(mock_df) == expected_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
